---
title: 3. Advanced RAG
date: 2025-09-18 22:59:17
permalink: /rag-advanced/
categories:
  - 基础知识
  - RAG
tags:
  - RAG
author: 
  name: xiao_sl
  link: https://github.com/xiaosl-cell
---

Advanced RAG (高级检索增强生成) 并不是一个有唯一、标准定义的术语，它更像是一个总称，指的是在基础RAG框架之上，为解决特定挑战而集成了一系列更复杂、更精细、更智能的技术和策略的优化RAG架构。

## 3.1 核心技术与策略

Advanced RAG通常包含以下一个或多个优化点，这些是区别于基础RAG的关键所在：

1. **检索前优化 (Pre-Retrieval)**

    在检索开始之前对用户查询和数据进行处理，以提升检索的效率和相关性。

    - **查询扩展 (Query Expansion)**: 当用户输入模糊或简单的查询时，系统会使用LLM自动扩展或重写查询，生成多个包含同义词、相关概念的变体，从而增加检索到相关文档的机会。

    - **查询路由 (Query Routing)**: 系统根据用户的查询意图，智能地决定去哪个知识库（例如，一个是产品手册，一个是财务报告）进行检索，甚至判断是否需要进行网络搜索。

    - **数据分块优化 (Chunking Optimization)**: 抛弃简单的按固定长度切分文档的方法。采用更智能的策略，如按句子或段落边界切分，或创建包含上下文的重叠块 (Overlapping Chunks)，以保证切分出的文本块语义完整。更高级的方法还包括根据文档的逻辑结构（如标题、章节）来分块。

2. **核心检索阶段优化 (Core Retrieval)**
    
    - **混合搜索 (Hybrid Search)**: 结合不同检索算法的优点。最常见的是关键词搜索 (Keyword Search, 如BM25) 和向量搜索 (Vector Search) 的结合。关键词搜索擅长匹配精确的术语和缩写，而向量搜索擅长理解语义和概念上的相似性。通过一个重排阶段 (Re-ranking) 将两者的结果智能地融合，得到最佳的排序。
    
    - **重排模型 (Re-ranking)**: 在初步检索到大量候选文档后（例如100篇），使用一个更复杂、更精准但计算量也更大的模型（通常是Cross-encoder）对这些候选文档进行二次排序，选出与查询最相关的Top-K个文档（例如5篇）送给LLM。这极大地提升了最终上下文的信噪比。

3. **检索后优化 (Post-Retrieval)**

    在将检索到的信息送入LLM之前，进行最后的处理，以优化上下文的质量。

    - **上下文压缩 (Context Compression)**: 即使是经过重排的文档块，也可能包含大量与用户问题无关的“噪音”。上下文压缩技术会识别并只提取出其中最关键、最相关的句子或信息，然后将这些精炼后的信息拼接起来，作为最终的上下文提供给LLM。这使得LLM可以在一个更短、更聚焦的上下文中工作，提升效率和准确性。

    - **上下文重排序 (Context Reordering)**: 研究表明，LLM在处理长上下文时存在“中间遗忘”问题，即它对上下文开头和结尾的信息记得最牢。因此，将最相关的文档块放在上下文的开头或结尾，可以帮助模型更好地利用关键信息。

4. **生成阶段优化 (Generation)**

    在LLM生成答案的环节进行优化。

    - **迭代式检索与生成 (Iterative Retrieval & Generation)**: 模型在生成答案的过程中，如果发现当前信息不足以回答，它可以主动决定发起新一轮的检索来补充知识，如此循环，直到能生成满意的答案。这模仿了人类解决复杂问题时的研究过程。

    - **知识图谱融合 (Knowledge Graph Integration)**: 将检索到的非结构化文本与结构化的知识图谱相结合。知识图谱能提供实体、关系等明确的知识，帮助LLM更好地理解实体关系和进行逻辑推理，生成更具深度的答案。