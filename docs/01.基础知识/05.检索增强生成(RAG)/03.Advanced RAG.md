---
title: 3. Advanced RAG
date: 2025-09-18 22:59:17
permalink: /rag-advanced/
categories:
  - 基础知识
  - RAG
tags:
  - RAG
author: 
  name: xiao_sl
  link: https://github.com/xiaosl-cell
---

Advanced RAG (高级检索增强生成)并不是一个具有标准定义的术语，它泛指在基础RAG架构之上，为应对特定挑战而引入一系列更复杂、精细且智能的技术与策略所形成的优化RAG集合体。本文将遵循RAG的工作流程，详细剖析这些优化策略。下图（源自 [huggingface](https://huggingface.co/learn/cookbook/en/advanced_rag)）以蓝色标注了RAG系统的各项潜在优化方向。

![Advanced RAG](https://qiniu.agiadventurer.com/advanced_rag.png)

## 3.1 知识库构建阶段

知识库构建阶段是整个RAG系统的基石，其优化策略直接影响到后续的检索效果。原始数据通常是非结构化的，需要经过一系列精细处理才能转化为可供模型高效检索的格式。高级RAG在此阶段的优化主要集中在 分块优化 (Chunking Optimization)、元数据丰富 (Metadata Enrichment) 和 索引结构优化 (Indexing Optimization) 三个方面。

### 3.1.1 分块优化 (Chunk Optimization)

#### 3.1.1.1 重叠分块

为了解决信息跨块分布的问题，我们可以采用重叠块策略，确保重要信息不会因为分块边界而丢失。

```python
def create_overlapping_chunks(text, chunk_size=512, overlap_size=50):
    """
    创建重叠的文本块
    """
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        
        # 下一个块的起始位置重叠
        start = start + chunk_size - overlap_size
        
        if start >= len(text):
            break
            
    return chunks
```
#### 3.1.1.2 递归分割

对于多级文档，我们可以使用 Langchain 提供的 RecursiveCharacterTextSplitter。RecursiveCharacterTextSplitter 采用递归分割策略，按照预定义的分隔符优先级顺序进行文档分割，确保在保持语义完整性的同时控制分块大小，以下是一个简单的示例：

```bash
pip install langchain
```

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

default_separators = [
    "\n## ",          # 二级标题
    "\n### ",         # 三级标题
    "\n#### ",        # 四级标题
    "\n\n",           # 段落分隔
    "\n",             # 行分隔
    " ",              # 空格
    ""                # 字符级
]


def create_recursive_splitter(chunk_size=1000, chunk_overlap=200):
    """
    创建递归字符文本分割器
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=default_separators,
        length_function=len,
    )
    return text_splitter

text_splitter = create_recursive_splitter()
chunks = text_splitter.split_text(document_text)
```

#### 3.1.1.3 语义分割

在实际应用中，由于预定义规则很死板，基于规则的分块方法很容易导致诸如检索上下文不完整或分块过大含有噪声等问题。因此最优雅的方法是基于语义进行分块。语义分块的宗旨是确保每个分块尽可能包含语义上独立的信息。
