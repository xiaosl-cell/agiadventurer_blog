---
title: 1. RAG基本概念
date: 2025-09-13 8:30:00
permalink: /rag-basics/
sidebar: true
article: true
author: 
  name: xiao_sl
  link: https://github.com/xiaosl-cell
categories: 
  - 基础知识
  - Rag
tags: 
  - Rag
---
## 1.1 基本概念

RAG（Retrieval-Augmented Generation，检索增强生成）是一种融合检索与生成技术的混合式AI模型框架，主要用于解决传统生成模型（如GPT系列）在生成内容时可能存在的知识局限性（如过时信息、缺乏领域针对性或事实性错误）问题，其核心思路是在生成答案前，先从外部知识库中动态检索相关上下文作为参考，再结合检索结果生成更准确、可靠且信息丰富的文本。

## 1.2 误区

RAG不要参考这张图，[Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/pdf/2005.11401)此论文第一次提出 RAG 这个叫法，在研究中，作者尝试将检索和生成做在一个模型体系中，但是目前实际生产中，RAG 不是这么做的

![错误RAG](https://qiniu.agiadventurer.com/rag-old.PNG)

## 1.3 RAG基本流程
目前主流的做法中，一个最简单的RAG的基本流程如下：
![RAG基本流程](https://qiniu.agiadventurer.com/rag-flow.png)

整个工作流可解构为两个主要阶段：知识库构建 和 推理与生成。

### 1.3.1 知识库构建与向量化索引

这个阶段的目标是**将外部知识源转化为可供高效检索的格式**。

- **知识源（External Knowledge）**：系统的起点是原始的外部知识语料，其形式可为非结构化文本、半结构化文档（如JSON、HTML）或结构化数据。这些是模型进行推理时所需依赖的外部事实依据。

- **文本分块与向量化嵌入（Chunking and Vectorization）**：
    - **分块（Chunking）**：为便于检索，原始文档被分割成语义完整且长度适中的文本块。分块策略（如固定长度、按段落分割、递归分割）对后续检索的粒度和效果有直接影响。

    - **向量化（Vectorization）**：系统采用一个预训练的嵌入模型将每个文本块映射到一个高维的密集向量空间中，生成其数值化的向量表示。

- **向量数据库（Vector Database）**：所有生成的文本块向量被加载并索引到一个专门的向量数据库中，便于后续的相似度检索。

### 1.3.2. 查询处理与增强生成

该阶段在接收到用户请求时被触发，主要为实时信息检索与内容生成。

- Prompt向量化：当系统接收到用户的输入（Prompt）后，会使用与知识库构建阶段相同的嵌入模型，将查询文本也转换为一个向量。

向量检索（Vector Search）：系统以该查询向量为基准，在向量数据库中执行相似性搜索。通过计算查询向量与数据库中已索引知识向量之间的距离或相似度（如余弦相似度、点积、欧氏距离），检索出与用户查询语义最相关的一个或多个知识块。检索结果通常是一个按相关性分数（Relevance Score）降序排列的列表。

上下文构建与提示工程（Context Construction and Prompt Engineering）：

策略性加工：根据预设的策略（例如，选择Top-K个结果、设定相关性得分阈值），系统从检索结果中筛选出最相关、信息量最丰富的知识块。

构建提示：这些筛选出的知识块作为动态上下文（Context），被整合到一个结构化的提示模板（Prompt Template）中。该模板将原始用户查询和检索到的上下文信息进行格式化编排，形成一个增强后的、信息完备的复合提示（Augmented Prompt）。模板的设计对于引导LLM的注意力、使其聚焦于所提供的上下文至关重要。

大语言模型生成（LLM Generation）：

推理：最终，这个增强后的提示被输入到大语言模型（LLM）的核心推理引擎中。

生成响应：LLM在生成回答时，其注意力机制会优先处理提示中明确提供的上下文信息。这使其能够生成基于外部知识源的、事实更为准确、内容更为具体的回复，而不是仅仅依赖其内部存储的、可能已过时的参数化知识。该机制有效缓解了模型的“知识幻觉”（Hallucination）问题。