---
title: 大模型API调用
date: 2025-09-05 15:56:29
permalink: /api/
categories:
  - 基础知识
tags:
  - llm调用
author: 
  name: xiao_sl
  link: https://github.com/xiaosl-cell
---

大模型API是指大模型（如自然语言处理模型、图像生成模型等）对外开放的应用程序接口（API）。开发者可以通过这些API，将大模型的能力集成到自己的应用中，以提高自身应用的智能化水平。

## 1. 简单示例

### 1.1 获取并配置API访问密钥（API Key）

首先，需要在提供大模型API服务的平台（如 OpenAI、DeepSeek、Hugging Face、Azure、Google Cloud等）注册并获取 API 密钥。这些平台会为每个账户生成一个唯一的API密钥，作为对服务的身份认证。

### 1.2 安装所需的 SDK 或库

以 Python 调用 OpenAI 为例，配置好python环境后安装 Python 客户端库。

```bash
pip install openai
```

### 1.3 编写代码

按照官方文档编写代码。以下为国内某代理提供的示例，为了安全，API_KEY与URL相关参数可以配置在环境变量中。

```python
from openai import OpenAI

client = OpenAI(
    api_key = "自己的API key",
    base_url = "模型提供API的URL"
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "你好？",
        }
    ],
    model="gpt-4o-mini", # 此处更换其它模型,请参考模型列表
)

print(chat_completion.choices[0].message.content)
```

### 1.4 API 接口兼容性

目前常用的大模型调用几乎都兼容了openai库，所以其他模型套路也几乎一致，在个别支持的功能上有细微差异，详细参见各大模型的API接入文档，本文内容以GPT为示例。

### 1.5 系统环境变量配置

为了提高安全性和便于管理，建议将 API 密钥和其他敏感信息配置为环境变量，而不是硬编码在代码中。

#### 1.5.1 Windows 系统配置

**方法一：命令行临时设置**
```cmd
set OPENAI_API_KEY=your-api-key-here
set OPENAI_BASE_URL=https://api.openai.com/v1
```

**方法二：PowerShell 设置**
```powershell
$env:OPENAI_API_KEY="your-api-key-here"
$env:OPENAI_BASE_URL="https://api.openai.com/v1"
```

**方法三：系统环境变量（永久设置）**
1. 右键"此电脑" → "属性" → "高级系统设置"
2. 点击"环境变量"按钮
3. 在"用户变量"或"系统变量"中点击"新建"
4. 变量名：`OPENAI_API_KEY`，变量值：你的API密钥
5. 同样方式添加 `OPENAI_BASE_URL` 变量

#### 1.5.2 Linux/macOS 系统配置

**临时设置（当前会话有效）**
```bash
export OPENAI_API_KEY="your-api-key-here"
export OPENAI_BASE_URL="https://api.openai.com/v1"
```

**永久设置**
```bash
# 编辑 ~/.bashrc 或 ~/.zshrc 文件
echo 'export OPENAI_API_KEY="your-api-key-here"' >> ~/.bashrc
echo 'export OPENAI_BASE_URL="https://api.openai.com/v1"' >> ~/.bashrc

# 重新加载配置
source ~/.bashrc
```

#### 1.5.3 Python 代码中使用环境变量

```python
import os
from openai import OpenAI

# 从环境变量读取配置
client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")  # 提供默认值
)

# 检查环境变量是否设置
if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("请设置 OPENAI_API_KEY 环境变量")

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "你好？",
        }
    ],
    model="gpt-4o-mini",
)

print(chat_completion.choices[0].message.content)
```

#### 1.5.4 使用 .env 文件（推荐）

**安装 python-dotenv**
```bash
pip install python-dotenv
```

**创建 .env 文件**
```env
# .env 文件内容
OPENAI_API_KEY=your-api-key-here
OPENAI_BASE_URL=https://api.openai.com/v1
MODEL_NAME=gpt-4o-mini
```

**Python 代码中加载 .env 文件**
```python
import os
from dotenv import load_dotenv
from openai import OpenAI

# 加载 .env 文件
load_dotenv()

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_BASE_URL")
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "你好？",
        }
    ],
    model=os.getenv("MODEL_NAME", "gpt-4o-mini"),  # 从环境变量读取模型名
)

print(chat_completion.choices[0].message.content)
```

#### 1.5.5 安全注意事项

- **不要将 .env 文件提交到版本控制系统**：在 `.gitignore` 中添加 `.env`
- **定期轮换 API 密钥**：建议每 3-6 个月更换一次
- **使用最小权限原则**：只授予必要的 API 权限
- **监控 API 使用情况**：定期检查 API 调用日志和费用

```gitignore
# .gitignore 文件示例
.env
.env.local
.env.*.local
*.key
config/secrets.json
```

## 2. 常用参数详解

### 2.1 messages

在基于 GPT-4 或类似模型的 API 中，`messages` 用于表示与模型的对话上下文。该参数是一个数组，数组中的每个元素表示一条消息。通过 `messages` 参数，开发者可以向模型传递对话历史，使模型能够基于上下文理解问题并给出合理的答案。

每个元素都是包含以下键值的字典：

| 键名 | 类型 | 必填 | 说明 |
|------|------|------|------|
| role | string | 是 | 对话角色标识，可选值：`system`（系统指令）、`user`（用户输入）、`assistant`（AI回复） |
| content | string | 是 | 对话内容文本（需注意不同模型对长度的限制） |

#### 2.1.1 使用规范

- 首个消息建议使用 `system` 角色设置AI行为模式（部分模型支持）
- 对话历史需按时间顺序排列，格式为交替的 `user` 和 `assistant` 消息
- 当前提问最后一条必须是 `user` 角色的消息

#### 2.1.2 示例结构

```python
messages = [
    {"role": "system", "content": "你是一个专业的技术文档翻译助手"},
    {"role": "user", "content": "请将'API'翻译成中文"},
    {"role": "assistant", "content": "应用程序接口"},
    {"role": "user", "content": "缩写形式呢？"}
]
```

### 2.2 model

`model` 参数用于指定调用的AI模型，其命名规则通常包含：

- **模型系列**：标识基础架构（如 gpt/gemma/claude）
- **版本号**：反映模型规模（如 -4/-3.5）或特性（如 -turbo/-instruct）
- **后缀标识**：标注特殊版本（如 -mini 精简版/-vision 多模态版）

#### 2.2.1 选择策略

| 优先级 | 选择标准 | 示例 |
|--------|----------|------|
| 精度优先 | 选择参数量大的版本 | gpt-4 > gpt-3.5 |
| 成本敏感 | 使用带 -mini/-tiny 后缀的轻量版本 | gpt-4o-mini |
| 响应速度 | 选用带 -turbo 标识的优化版本 | gpt-3.5-turbo |
| 专业领域 | 选择特定领域增强模型 | -medical 医疗版 |


### 2.3 temperature

`temperature` 参数控制生成文本的随机性程度，是影响大模型输出风格的核心参数之一。

#### 2.3.1 参数说明

| 属性 | 说明 |
|------|------|
| 类型 | 浮点数 |
| 默认值 | 1.0（不同模型可能有差异） |
| 取值范围 | 0.0 ~ 2.0（部分模型可扩展至 5.0） |
| 作用原理 | 调整输出 token 的概率分布：值越高选择低概率词的可能性越大，值越低则倾向于高概率词 |

#### 2.3.2 使用策略

| 典型值 | 适用场景 | 输出特征 | 示例场景 |
|--------|----------|----------|----------|
| 0.0~0.3 | 事实性问答/代码生成 | 确定性高，重复率低 | 法律文件解析、数学计算 |
| 0.4~0.7 | 常规对话/内容总结 | 平衡创意与逻辑 | 客服对话、会议纪要生成 |
| 0.8~1.2 | 创意写作/头脑风暴 | 多样性显著增强 | 诗歌生成、营销文案创作 |
| 1.3+ | 探索性实验/艺术创作 | 高度随机，可能产生意外结果 | 抽象艺术描述、开放式故事续写 |

#### 2.3.3 注意事项

- **悬崖效应**：当 temperature > 1.5 时，输出质量可能断崖式下降
- **零值风险**：设为 0 时可能触发模型的「贪婪搜索」模式，导致：
  - 重复性输出增加
  - 长文本生成质量下降
  - 部分模型会强制启用确定性算法
- **模型差异**：不同架构模型对 temperature 的敏感度不同（如 GPT 系列比 Claude 更敏感）

### 2.4 top_p

`top_p` 参数是另一种控制生成文本随机性的方式，使用核采样，即通过累积概率的方式选择候选词。

#### 2.4.1 参数说明

- `top_p` 是一个介于 0 和 1 之间的值，表示模型选取的概率阈值
- 例如，当 `top_p=0.9` 时，模型只会选择概率累积到 90% 内的候选词进行生成

#### 2.4.2 使用策略

- **较低的 top_p 值**（如 0.6-0.7）能限制词汇选择的范围，生成的文本更加聚焦
- **较高的 top_p 值**（如 0.9）能允许更多的词汇参与选择，生成的文本更具多样性

#### 2.4.3 核心机制

**概率分布示例**：
```
["car"(0.4), "bus"(0.3), "train"(0.2), "ship"(0.1)]
```

当 `top_p=0.7` 时：
- 累积概率：car(0.4) → car+bus=0.7（达到阈值）
- 候选词范围：["car", "bus"]（排除后 30% 的 train/ship）

#### 2.4.4 代码示例

```python
response = client.chat.completions.create(
    messages=[{"role": "user", "content": "写一首关于秋天的诗"}],
    model="gpt-4o-mini",
    top_p=0.85  # 允许适度发散
)
```

#### 2.4.5 注意事项

- **参数互斥**：通常与 `temperature` 二选一调节（避免同时设 `top_p=0.5` 和 `temperature=0`）
- **动态筛选**：实际候选词数量会随上下文动态变化（不同于 `top_k` 的固定数量筛选）
- **模型支持**：部分轻量化模型可能不支持该参数（如 gpt-4o-mini 支持，但 gemma-2b 可能受限）
- **零值风险**：`top_p=0` 时可能完全禁用采样机制（需查阅具体模型文档）

### 2.5 参数组合建议

#### 2.5.1 常见组合策略

```python
# 精确回答场景
response = client.chat.completions.create(
    messages=messages,
    model="gpt-4o-mini",
    temperature=0.2,
    # 不设置 top_p，让 temperature 主导
)

# 创意写作场景
response = client.chat.completions.create(
    messages=messages,
    model="gpt-4o-mini",
    top_p=0.9,
    # 不设置 temperature，让 top_p 主导
)

# 平衡场景
response = client.chat.completions.create(
    messages=messages,
    model="gpt-4o-mini",
    temperature=0.7,
    # 或者使用 top_p=0.8
)
```
## 3. 其他调用方式

### 3.1 JavaScript

在 JavaScript 环境中，可以使用 fetch API 或 axios 等库来调用大模型API。

```javascript
const fetch = require('node-fetch'); // 如果是 Node.js 环境

const API_KEY = 'your-api-key'; // 你的 OpenAI API 密钥
const url = 'https://api.openai.com/v1/chat/completions';

const headers = {
  'Content-Type': 'application/json',
  'Authorization': `Bearer ${API_KEY}`,
};

const data = {
  model: "gpt-4o-mini",
  messages: [
    {
      "role": "user",
      "content": "Translate the following English text to French: 'Hello, how are you?'"
    }
  ],
  max_tokens: 60,
  temperature: 0.7
};

fetch(url, {
  method: 'POST',
  headers: headers,
  body: JSON.stringify(data),
})
  .then(response => response.json())
  .then(data => console.log(data.choices[0].message.content))
  .catch(error => console.error('Error:', error));
```

#### 3.1.1 现代 JavaScript (ES6+) 写法

```javascript
// 使用 async/await
async function callOpenAI(prompt) {
  try {
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [{ role: "user", content: prompt }],
        temperature: 0.7,
        max_tokens: 150
      }),
    });

    const data = await response.json();
    return data.choices[0].message.content;
  } catch (error) {
    console.error('API调用失败:', error);
    throw error;
  }
}

// 使用示例
callOpenAI("解释什么是人工智能")
  .then(result => console.log(result))
  .catch(error => console.error(error));
```

### 3.2 curl 接口

其本质是一个 HTTP 接口，所以你也可以用任何语言与方式发送 HTTP 请求来实现调用。

```bash
curl https://api.openai.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your-api-key" \
  -d '{
    "model": "gpt-4o-mini",
    "messages": [
      {
        "role": "user",
        "content": "Translate the following English text to French: '\''Hello, how are you?'\''"
      }
    ],
    "max_tokens": 60,
    "temperature": 0.7
  }'
```

#### 3.2.1 使用环境变量的 curl 示例

```bash
# 设置环境变量
export OPENAI_API_KEY="your-api-key"
export OPENAI_BASE_URL="https://api.openai.com/v1"

# 调用API
curl $OPENAI_BASE_URL/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -d '{
    "model": "gpt-4o-mini",
    "messages": [
      {"role": "system", "content": "你是一个专业的翻译助手"},
      {"role": "user", "content": "请将以下英文翻译成中文：Hello, how are you?"}
    ],
    "temperature": 0.3
  }'
```

### 3.3 Java SpringAI

SpringAI 是 Spring 官方推出的 AI 集成框架，提供统一 API 规范的大模型调用能力，支持 OpenAI、Azure OpenAI、HuggingFace 等主流平台。

#### 3.3.1 环境配置

**步骤 1：添加依赖**

```xml
<!-- pom.xml -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
    <version>0.8.0</version> <!-- 建议使用最新版本 -->
</dependency>
```

**步骤 2：配置参数**

```properties
# application.properties
spring.ai.openai.api-key=your-api-key
spring.ai.openai.base-url=https://api.openai.com/v1
```

#### 3.3.2 基础调用示例

```java
import org.springframework.ai.client.AiClient;
import org.springframework.ai.prompt.Prompt;
import org.springframework.ai.prompt.messages.Message;
import org.springframework.ai.prompt.messages.SystemMessage;
import org.springframework.ai.prompt.messages.UserMessage;
import org.springframework.ai.openai.OpenAiChatOptions;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RestController;

import java.util.List;

@RestController
public class AiController {

    @Autowired
    private AiClient aiClient;

    @GetMapping("/chat")
    public String chat() {
        // 构建对话上下文
        List<Message> messages = List.of(
            new SystemMessage("你是一个Java开发助手"),
            new UserMessage("如何用Spring Boot创建REST API?")
        );

        // 创建请求
        Prompt prompt = new Prompt(
            messages,
            OpenAiChatOptions.builder()
                .withModel("gpt-4o-mini")
                .withTemperature(0.7)
                .withMaxTokens(200)
                .withTopP(0.9)
                .build()
        );

        // 发送请求并获取响应
        return aiClient.generate(prompt).getGeneration().getText();
    }
}
```

#### 3.3.3 流式响应

```java
import org.springframework.web.servlet.mvc.method.annotation.SseEmitter;
import java.io.IOException;

@GetMapping("/stream")
public SseEmitter streamChat() {
    SseEmitter emitter = new SseEmitter();

    aiClient.stream(new Prompt(
        List.of(new UserMessage("用Java实现快速排序")),
        OpenAiChatOptions.builder().withModel("gpt-4o-mini").build()
    )).subscribe(
        chunk -> {
            try {
                emitter.send(chunk.getGeneration().getText());
            } catch (IOException e) {
                throw new RuntimeException(e);
            }
        },
        emitter::completeWithError,
        emitter::complete
    );

    return emitter;
}
```

#### 3.3.4 配置项说明

| 参数路径 | 类型 | 默认值 | 说明 |
|----------|------|--------|------|
| spring.ai.openai.api-key | String | - | API 访问密钥（必填） |
| spring.ai.openai.base-url | String | OpenAI 官方URL | 官方URL/代理地址 |
| spring.ai.openai.chat.options.temperature | Double | 0.7 | 随机性控制参数 |
| spring.ai.openai.chat.options.max-tokens | Integer | 2000 | 响应最大长度限制 |

#### 3.3.5 注意事项

- **版本兼容性**：SpringAI 0.8.x 需要 Spring Boot 3.2+
- **JDK 最低要求 17**
- **性能优化**：
  - 使用 `@Cacheable` 缓存高频请求
  - 启用 `spring.ai.openai.enable-metrics=true` 进行性能监控

### 3.4 其他框架方式对比

| 方式 | 开发成本 | 灵活性 | 适合场景 | 典型用户 |
|------|----------|--------|----------|----------|
| 原生API | 高 | 极高 | 核心业务/定制需求 | 技术团队 |
| LangChain | 中 | 高 | 复杂AI工作流 | AI工程师 |
| LlamaIndex | 中 | 中 | 文档问答系统 | 数据团队 |
| Dify/FastGPT | 低 | 低 | 标准化业务场景 | 企业开发、产品经理 |

